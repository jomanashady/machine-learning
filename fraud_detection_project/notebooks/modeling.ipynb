{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # 02 - Healthcare Fraud Detection: Modeling\n",
    "# \n",
    "# ## Project Overview\n",
    "# This notebook covers:\n",
    "# 1. Data preparation and splitting\n",
    "# 2. Handling class imbalance\n",
    "# 3. Model training (multiple algorithms as per project requirements)\n",
    "# 4. Hyperparameter tuning\n",
    "# 5. Model comparison\n",
    "# \n",
    "# **Team:** [Your Team Name]\n",
    "# **Date:** [Current Date]\n",
    "\n",
    "# %%\n",
    "# Cell 1: Import Libraries with debugger fix\n",
    "import os\n",
    "# Suppress debugger warnings\n",
    "os.environ['PYDEVD_DISABLE_FILE_VALIDATION'] = '1'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                           roc_auc_score, confusion_matrix, classification_report,\n",
    "                           precision_recall_curve, roc_curve, average_precision_score)\n",
    "\n",
    "# Imbalance handling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "# Models (All required models from project description)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Shape: (5410, 40)\n",
      "Fraud rate: 9.35%\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provider</th>\n",
       "      <th>Claims_InscClaimAmtReimbursed_count</th>\n",
       "      <th>Claims_InscClaimAmtReimbursed_sum</th>\n",
       "      <th>Claims_InscClaimAmtReimbursed_mean</th>\n",
       "      <th>Claims_InscClaimAmtReimbursed_std</th>\n",
       "      <th>Claims_InscClaimAmtReimbursed_max</th>\n",
       "      <th>Claims_InscClaimAmtReimbursed_min</th>\n",
       "      <th>Claims_DeductibleAmtPaid_sum</th>\n",
       "      <th>Claims_DeductibleAmtPaid_mean</th>\n",
       "      <th>Claims_DeductibleAmtPaid_std</th>\n",
       "      <th>...</th>\n",
       "      <th>Beneficiary_Gender_&lt;lambda&gt;</th>\n",
       "      <th>Beneficiary_Race_nunique</th>\n",
       "      <th>UniquePhysicians_Count</th>\n",
       "      <th>UniqueBeneficiaries_Count</th>\n",
       "      <th>TotalClaims_Count</th>\n",
       "      <th>ClaimTimeSpan_Days</th>\n",
       "      <th>PotentialFraud</th>\n",
       "      <th>Avg_Reimbursement_per_Beneficiary</th>\n",
       "      <th>Claims_per_Beneficiary</th>\n",
       "      <th>Reimbursement_per_Claim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRV51001</td>\n",
       "      <td>25</td>\n",
       "      <td>104640</td>\n",
       "      <td>4185.600000</td>\n",
       "      <td>10796.091144</td>\n",
       "      <td>42000</td>\n",
       "      <td>10</td>\n",
       "      <td>5340.0</td>\n",
       "      <td>213.600000</td>\n",
       "      <td>436.009174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>358</td>\n",
       "      <td>0</td>\n",
       "      <td>4360.000000</td>\n",
       "      <td>1.041667</td>\n",
       "      <td>4185.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRV51003</td>\n",
       "      <td>132</td>\n",
       "      <td>605670</td>\n",
       "      <td>4588.409091</td>\n",
       "      <td>7309.794729</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "      <td>66286.0</td>\n",
       "      <td>502.166667</td>\n",
       "      <td>534.582439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418803</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>117</td>\n",
       "      <td>132</td>\n",
       "      <td>356</td>\n",
       "      <td>1</td>\n",
       "      <td>5176.666667</td>\n",
       "      <td>1.128205</td>\n",
       "      <td>4588.409091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRV51004</td>\n",
       "      <td>149</td>\n",
       "      <td>52170</td>\n",
       "      <td>350.134228</td>\n",
       "      <td>689.963754</td>\n",
       "      <td>3300</td>\n",
       "      <td>0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>2.080537</td>\n",
       "      <td>11.166744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>138</td>\n",
       "      <td>149</td>\n",
       "      <td>358</td>\n",
       "      <td>0</td>\n",
       "      <td>378.043478</td>\n",
       "      <td>1.079710</td>\n",
       "      <td>350.134228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRV51005</td>\n",
       "      <td>1165</td>\n",
       "      <td>280910</td>\n",
       "      <td>241.124464</td>\n",
       "      <td>491.556392</td>\n",
       "      <td>4080</td>\n",
       "      <td>0</td>\n",
       "      <td>3700.0</td>\n",
       "      <td>3.175966</td>\n",
       "      <td>17.026584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.420202</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>495</td>\n",
       "      <td>1165</td>\n",
       "      <td>376</td>\n",
       "      <td>1</td>\n",
       "      <td>567.494949</td>\n",
       "      <td>2.353535</td>\n",
       "      <td>241.124464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRV51007</td>\n",
       "      <td>72</td>\n",
       "      <td>33710</td>\n",
       "      <td>468.194444</td>\n",
       "      <td>1433.769116</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>3264.0</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>214.820724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>58</td>\n",
       "      <td>72</td>\n",
       "      <td>356</td>\n",
       "      <td>0</td>\n",
       "      <td>581.206897</td>\n",
       "      <td>1.241379</td>\n",
       "      <td>468.194444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Provider  Claims_InscClaimAmtReimbursed_count  \\\n",
       "0  PRV51001                                   25   \n",
       "1  PRV51003                                  132   \n",
       "2  PRV51004                                  149   \n",
       "3  PRV51005                                 1165   \n",
       "4  PRV51007                                   72   \n",
       "\n",
       "   Claims_InscClaimAmtReimbursed_sum  Claims_InscClaimAmtReimbursed_mean  \\\n",
       "0                             104640                         4185.600000   \n",
       "1                             605670                         4588.409091   \n",
       "2                              52170                          350.134228   \n",
       "3                             280910                          241.124464   \n",
       "4                              33710                          468.194444   \n",
       "\n",
       "   Claims_InscClaimAmtReimbursed_std  Claims_InscClaimAmtReimbursed_max  \\\n",
       "0                       10796.091144                              42000   \n",
       "1                        7309.794729                              57000   \n",
       "2                         689.963754                               3300   \n",
       "3                         491.556392                               4080   \n",
       "4                        1433.769116                              10000   \n",
       "\n",
       "   Claims_InscClaimAmtReimbursed_min  Claims_DeductibleAmtPaid_sum  \\\n",
       "0                                 10                        5340.0   \n",
       "1                                  0                       66286.0   \n",
       "2                                  0                         310.0   \n",
       "3                                  0                        3700.0   \n",
       "4                                  0                        3264.0   \n",
       "\n",
       "   Claims_DeductibleAmtPaid_mean  Claims_DeductibleAmtPaid_std  ...  \\\n",
       "0                     213.600000                    436.009174  ...   \n",
       "1                     502.166667                    534.582439  ...   \n",
       "2                       2.080537                     11.166744  ...   \n",
       "3                       3.175966                     17.026584  ...   \n",
       "4                      45.333333                    214.820724  ...   \n",
       "\n",
       "   Beneficiary_Gender_<lambda>  Beneficiary_Race_nunique  \\\n",
       "0                     0.375000                         2   \n",
       "1                     0.418803                         3   \n",
       "2                     0.326087                         3   \n",
       "3                     0.420202                         3   \n",
       "4                     0.465517                         2   \n",
       "\n",
       "   UniquePhysicians_Count  UniqueBeneficiaries_Count  TotalClaims_Count  \\\n",
       "0                      14                         24                 25   \n",
       "1                      44                        117                132   \n",
       "2                      38                        138                149   \n",
       "3                       6                        495               1165   \n",
       "4                      10                         58                 72   \n",
       "\n",
       "   ClaimTimeSpan_Days  PotentialFraud  Avg_Reimbursement_per_Beneficiary  \\\n",
       "0                 358               0                        4360.000000   \n",
       "1                 356               1                        5176.666667   \n",
       "2                 358               0                         378.043478   \n",
       "3                 376               1                         567.494949   \n",
       "4                 356               0                         581.206897   \n",
       "\n",
       "   Claims_per_Beneficiary  Reimbursement_per_Claim  \n",
       "0                1.041667              4185.600000  \n",
       "1                1.128205              4588.409091  \n",
       "2                1.079710               350.134228  \n",
       "3                2.353535               241.124464  \n",
       "4                1.241379               468.194444  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 2: Load Processed Data\n",
    "provider_features = pd.read_csv('../data/processed/provider_features_final.csv')\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {provider_features.shape}\")\n",
    "print(f\"Fraud rate: {provider_features['PotentialFraud'].mean():.2%}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "display(provider_features.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Data Preparation Function\n",
    "def prepare_data(df, test_size=0.2, val_size=0.1):\n",
    "    \"\"\"\n",
    "    Prepare data for modeling with train/validation/test splits\n",
    "    \"\"\"\n",
    "    # Separate features and target\n",
    "    X = df.drop(['Provider', 'PotentialFraud'], axis=1)\n",
    "    y = df['PotentialFraud']\n",
    "    \n",
    "    # Handle any remaining non-numeric columns\n",
    "    for col in X.select_dtypes(include=['object']).columns:\n",
    "        X = X.drop(columns=[col])\n",
    "    \n",
    "    # First split: train+val vs test\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Second split: train vs validation\n",
    "    val_ratio = val_size / (1 - test_size)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=val_ratio, random_state=42, stratify=y_temp\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Convert back to DataFrames\n",
    "    X_train = pd.DataFrame(X_train_scaled, columns=X.columns, index=X_train.index)\n",
    "    X_val = pd.DataFrame(X_val_scaled, columns=X.columns, index=X_val.index)\n",
    "    X_test = pd.DataFrame(X_test_scaled, columns=X.columns, index=X_test.index)\n",
    "    \n",
    "    print(\"Data splits created:\")\n",
    "    print(f\"  Training set: {X_train.shape}, Fraud rate: {y_train.mean():.2%}\")\n",
    "    print(f\"  Validation set: {X_val.shape}, Fraud rate: {y_val.mean():.2%}\")\n",
    "    print(f\"  Test set: {X_test.shape}, Fraud rate: {y_test.mean():.2%}\")\n",
    "    print(f\"  Number of features: {X_train.shape[1]}\")\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splits created:\n",
      "  Training set: (3787, 38), Fraud rate: 9.35%\n",
      "  Validation set: (541, 38), Fraud rate: 9.43%\n",
      "  Test set: (1082, 38), Fraud rate: 9.33%\n",
      "  Number of features: 38\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Create Data Splits\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, scaler = prepare_data(provider_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Class Imbalance Handling ===\n",
      "Original training fraud rate: 9.35%\n",
      "After SMOTE (30% fraud): (4462, 38), Fraud rate: 23.06%\n",
      "\n",
      "Class distribution for weighting:\n",
      "  Class 0 (Non-Fraud): 3433\n",
      "  Class 1 (Fraud): 354\n",
      "After Random Under Sampling: (1534, 38), Fraud rate: 23.08%\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Handle Class Imbalance\n",
    "print(\"=== Class Imbalance Handling ===\")\n",
    "print(f\"Original training fraud rate: {y_train.mean():.2%}\")\n",
    "\n",
    "# Strategy 1: SMOTE\n",
    "smote = SMOTE(random_state=42, sampling_strategy=0.3)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "print(f\"After SMOTE (30% fraud): {X_train_smote.shape}, Fraud rate: {y_train_smote.mean():.2%}\")\n",
    "\n",
    "# Strategy 2: Class weighting (for comparison)\n",
    "print(f\"\\nClass distribution for weighting:\")\n",
    "print(f\"  Class 0 (Non-Fraud): {sum(y_train == 0)}\")\n",
    "print(f\"  Class 1 (Fraud): {sum(y_train == 1)}\")\n",
    "\n",
    "# Strategy 3: Random Under Sampling (for comparison)\n",
    "rus = RandomUnderSampler(random_state=42, sampling_strategy=0.3)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n",
    "print(f\"After Random Under Sampling: {X_train_rus.shape}, Fraud rate: {y_train_rus.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Train Multiple Models (All required models)\n",
    "def train_models(X_train, y_train, X_val, y_val, use_class_weight=True):\n",
    "    \"\"\"\n",
    "    Train multiple classification models as per project requirements\n",
    "    \"\"\"\n",
    "    # Calculate class weights if needed\n",
    "    class_weight = None\n",
    "    if use_class_weight:\n",
    "        class_weight = 'balanced'\n",
    "    \n",
    "    # Define all models from project requirements plus some extras\n",
    "    models = {\n",
    "        # Required by project: Logistic Regression\n",
    "        'Logistic Regression': LogisticRegression(\n",
    "            class_weight=class_weight,\n",
    "            random_state=42,\n",
    "            max_iter=1000\n",
    "        ),\n",
    "        \n",
    "        # Required by project: Decision Tree\n",
    "        'Decision Tree': DecisionTreeClassifier(\n",
    "            class_weight=class_weight,\n",
    "            random_state=42,\n",
    "            max_depth=10\n",
    "        ),\n",
    "        \n",
    "        # Required by project: Random Forest\n",
    "        'Random Forest': RandomForestClassifier(\n",
    "            class_weight=class_weight,\n",
    "            random_state=42,\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            n_jobs=1\n",
    "        ),\n",
    "        \n",
    "        # Required by project: Gradient Boosting\n",
    "        'Gradient Boosting': GradientBoostingClassifier(\n",
    "            random_state=42,\n",
    "            n_estimators=100,\n",
    "            max_depth=5,\n",
    "            learning_rate=0.1\n",
    "        ),\n",
    "        \n",
    "        # Required by project: SVM\n",
    "        'SVM (Linear)': SVC(\n",
    "            class_weight=class_weight,\n",
    "            random_state=42,\n",
    "            probability=True,\n",
    "            kernel='linear'\n",
    "        ),\n",
    "        \n",
    "        # SVM with RBF kernel (for comparison)\n",
    "        'SVM (RBF)': SVC(\n",
    "            class_weight=class_weight,\n",
    "            random_state=42,\n",
    "            probability=True,\n",
    "            kernel='rbf'\n",
    "        ),\n",
    "        \n",
    "        # Additional models for comparison\n",
    "        'Naive Bayes': GaussianNB(),\n",
    "        \n",
    "        'K-Nearest Neighbors': KNeighborsClassifier(\n",
    "            n_neighbors=5,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        \n",
    "        'AdaBoost': GradientBoostingClassifier(  # Using Gradient Boosting as AdaBoost alternative\n",
    "            random_state=42,\n",
    "            n_estimators=50,\n",
    "            max_depth=3,\n",
    "            learning_rate=0.1\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nTraining {model_name}...\")\n",
    "        \n",
    "        try:\n",
    "            # Train model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Predict on validation set\n",
    "            y_pred = model.predict(X_val)\n",
    "            y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "            \n",
    "            # Calculate metrics\n",
    "            metrics = {\n",
    "                'Accuracy': accuracy_score(y_val, y_pred),\n",
    "                'Precision': precision_score(y_val, y_pred, zero_division=0),\n",
    "                'Recall': recall_score(y_val, y_pred),\n",
    "                'F1-Score': f1_score(y_val, y_pred),\n",
    "                'ROC-AUC': roc_auc_score(y_val, y_pred_proba),\n",
    "                'PR-AUC': average_precision_score(y_val, y_pred_proba)\n",
    "            }\n",
    "            \n",
    "            results[model_name] = {\n",
    "                'model': model,\n",
    "                'metrics': metrics,\n",
    "                'predictions': y_pred,\n",
    "                'probabilities': y_pred_proba\n",
    "            }\n",
    "            \n",
    "            # Print metrics\n",
    "            print(f\"  F1-Score: {metrics['F1-Score']:.4f}\")\n",
    "            print(f\"  Recall: {metrics['Recall']:.4f}\")\n",
    "            print(f\"  Precision: {metrics['Precision']:.4f}\")\n",
    "            print(f\"  ROC-AUC: {metrics['ROC-AUC']:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error training {model_name}: {str(e)}\")\n",
    "            results[model_name] = None\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training Models with SMOTE ===\n",
      "\n",
      "Training Logistic Regression...\n",
      "  F1-Score: 0.6481\n",
      "  Recall: 0.6863\n",
      "  Precision: 0.6140\n",
      "  ROC-AUC: 0.9405\n",
      "\n",
      "Training Decision Tree...\n",
      "  F1-Score: 0.6545\n",
      "  Recall: 0.7059\n",
      "  Precision: 0.6102\n",
      "  ROC-AUC: 0.7893\n",
      "\n",
      "Training Random Forest...\n",
      "  F1-Score: 0.7156\n",
      "  Recall: 0.7647\n",
      "  Precision: 0.6724\n",
      "  ROC-AUC: 0.9524\n",
      "\n",
      "Training Gradient Boosting...\n",
      "  F1-Score: 0.6465\n",
      "  Recall: 0.6275\n",
      "  Precision: 0.6667\n",
      "  ROC-AUC: 0.9409\n",
      "\n",
      "Training SVM (Linear)...\n",
      "  F1-Score: 0.6316\n",
      "  Recall: 0.7059\n",
      "  Precision: 0.5714\n",
      "  ROC-AUC: 0.9368\n",
      "\n",
      "Training SVM (RBF)...\n",
      "  F1-Score: 0.6286\n",
      "  Recall: 0.6471\n",
      "  Precision: 0.6111\n",
      "  ROC-AUC: 0.9238\n",
      "\n",
      "Training Naive Bayes...\n",
      "  F1-Score: 0.5857\n",
      "  Recall: 0.8039\n",
      "  Precision: 0.4607\n",
      "  ROC-AUC: 0.9093\n",
      "\n",
      "Training K-Nearest Neighbors...\n",
      "  F1-Score: 0.5873\n",
      "  Recall: 0.7255\n",
      "  Precision: 0.4933\n",
      "  ROC-AUC: 0.9069\n",
      "\n",
      "Training AdaBoost...\n",
      "  F1-Score: 0.6909\n",
      "  Recall: 0.7451\n",
      "  Precision: 0.6441\n",
      "  ROC-AUC: 0.9508\n",
      "\n",
      "=== Training Models with Class Weighting ===\n",
      "\n",
      "Training Logistic Regression...\n",
      "  F1-Score: 0.5478\n",
      "  Recall: 0.8431\n",
      "  Precision: 0.4057\n",
      "  ROC-AUC: 0.9402\n",
      "\n",
      "Training Decision Tree...\n",
      "  F1-Score: 0.6400\n",
      "  Recall: 0.7843\n",
      "  Precision: 0.5405\n",
      "  ROC-AUC: 0.8626\n",
      "\n",
      "Training Random Forest...\n",
      "  F1-Score: 0.7455\n",
      "  Recall: 0.8039\n",
      "  Precision: 0.6949\n",
      "  ROC-AUC: 0.9517\n",
      "\n",
      "Training Gradient Boosting...\n",
      "  F1-Score: 0.6522\n",
      "  Recall: 0.5882\n",
      "  Precision: 0.7317\n",
      "  ROC-AUC: 0.9504\n",
      "\n",
      "Training SVM (Linear)...\n",
      "  F1-Score: 0.5570\n",
      "  Recall: 0.8627\n",
      "  Precision: 0.4112\n",
      "  ROC-AUC: 0.9382\n",
      "\n",
      "Training SVM (RBF)...\n",
      "  F1-Score: 0.5409\n",
      "  Recall: 0.8431\n",
      "  Precision: 0.3981\n",
      "  ROC-AUC: 0.9281\n",
      "\n",
      "Training Naive Bayes...\n",
      "  F1-Score: 0.5606\n",
      "  Recall: 0.7255\n",
      "  Precision: 0.4568\n",
      "  ROC-AUC: 0.9160\n",
      "\n",
      "Training K-Nearest Neighbors...\n",
      "  F1-Score: 0.5581\n",
      "  Recall: 0.4706\n",
      "  Precision: 0.6857\n",
      "  ROC-AUC: 0.8830\n",
      "\n",
      "Training AdaBoost...\n",
      "  F1-Score: 0.6444\n",
      "  Recall: 0.5686\n",
      "  Precision: 0.7436\n",
      "  ROC-AUC: 0.9594\n",
      "\n",
      "=== Training Models with Random Under Sampling ===\n",
      "\n",
      "Training Logistic Regression...\n",
      "  F1-Score: 0.6239\n",
      "  Recall: 0.6667\n",
      "  Precision: 0.5862\n",
      "  ROC-AUC: 0.9448\n",
      "\n",
      "Training Decision Tree...\n",
      "  F1-Score: 0.5938\n",
      "  Recall: 0.7451\n",
      "  Precision: 0.4935\n",
      "  ROC-AUC: 0.8142\n",
      "\n",
      "Training Random Forest...\n",
      "  F1-Score: 0.7009\n",
      "  Recall: 0.8039\n",
      "  Precision: 0.6212\n",
      "  ROC-AUC: 0.9532\n",
      "\n",
      "Training Gradient Boosting...\n",
      "  F1-Score: 0.7258\n",
      "  Recall: 0.8824\n",
      "  Precision: 0.6164\n",
      "  ROC-AUC: 0.9541\n",
      "\n",
      "Training SVM (Linear)...\n",
      "  F1-Score: 0.6250\n",
      "  Recall: 0.6863\n",
      "  Precision: 0.5738\n",
      "  ROC-AUC: 0.9363\n",
      "\n",
      "Training SVM (RBF)...\n",
      "  F1-Score: 0.6364\n",
      "  Recall: 0.6863\n",
      "  Precision: 0.5932\n",
      "  ROC-AUC: 0.9300\n",
      "\n",
      "Training Naive Bayes...\n",
      "  F1-Score: 0.5693\n",
      "  Recall: 0.7647\n",
      "  Precision: 0.4535\n",
      "  ROC-AUC: 0.9215\n",
      "\n",
      "Training K-Nearest Neighbors...\n",
      "  F1-Score: 0.6018\n",
      "  Recall: 0.6667\n",
      "  Precision: 0.5484\n",
      "  ROC-AUC: 0.9330\n",
      "\n",
      "Training AdaBoost...\n",
      "  F1-Score: 0.7167\n",
      "  Recall: 0.8431\n",
      "  Precision: 0.6232\n",
      "  ROC-AUC: 0.9610\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Train Models with Different Imbalance Strategies\n",
    "print(\"=== Training Models with SMOTE ===\")\n",
    "results_smote = train_models(X_train_smote, y_train_smote, X_val, y_val, use_class_weight=False)\n",
    "\n",
    "print(\"\\n=== Training Models with Class Weighting ===\")\n",
    "results_weighted = train_models(X_train, y_train, X_val, y_val, use_class_weight=True)\n",
    "\n",
    "print(\"\\n=== Training Models with Random Under Sampling ===\")\n",
    "results_rus = train_models(X_train_rus, y_train_rus, X_val, y_val, use_class_weight=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
